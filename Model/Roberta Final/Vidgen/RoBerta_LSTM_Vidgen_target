{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RoBerta_LSTM_Vidgen_target","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JXKj04qfZWOa","executionInfo":{"status":"ok","timestamp":1631164982766,"user_tz":420,"elapsed":383,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["# This module trains base on the Vidgen data with target against Asian."],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pp3_2ZLq6NS","executionInfo":{"status":"ok","timestamp":1631164989417,"user_tz":420,"elapsed":6449,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"0ff480b4-963f-4f5d-c775-8ba4e4961740"},"source":["from datetime import datetime\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import re, string\n","import time\n","import random\n","import gc\n","import os, sys\n","import json\n","from copy import deepcopy\n","\n","#####\n","# !pip install gdown\n","!pip install transformers\n","pd.options.display.max_colwidth = 500\n","#####\n","\n","import torch\n","##### SET SEEED ######\n","\n","######################\n","\n","# !pip install simpletransfomers\n","\n","from transformers import BertForSequenceClassification, AdamW , BertConfig, BertModel\n","from transformers import RobertaConfig, RobertaModel, RobertaTokenizer, RobertaForSequenceClassification\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import LineByLineTextDataset\n","\n","from torch.nn import LSTM, Dropout, Linear, BCELoss, CrossEntropyLoss, Softmax, ReLU, LeakyReLU, Tanh\n","from torch.nn.functional import softmax, relu\n","from torch.nn.utils.rnn import pack_padded_sequence\n","from torch.utils.data.dataset import Subset\n","\n","\n","\n","\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n","\n","%load_ext autoreload \n","%autoreload 2"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzEvkGACWMqX","executionInfo":{"status":"ok","timestamp":1631164989420,"user_tz":420,"elapsed":17,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"f59f2898-c0f8-4ff3-e4c9-11bcb7d89abd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUYifLXWu1D0","executionInfo":{"status":"ok","timestamp":1631164989421,"user_tz":420,"elapsed":12,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"e186f6a4-ab01-4a67-e375-300d4e5316a8"},"source":["!ls \"/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech/Model\""],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["'Bert Models'   models.py   __pycache__   RoBerta  'Roberta Final'\n"]}]},{"cell_type":"code","metadata":{"id":"f6srHxsX4FhM","executionInfo":{"status":"ok","timestamp":1631164989421,"user_tz":420,"elapsed":7,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["PATH_PREFIX = '/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"C8keHP8s6Fj4","executionInfo":{"status":"ok","timestamp":1631164990104,"user_tz":420,"elapsed":689,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["sys.path.append('/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech/utils')\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech/Model')\n","\n","from models import *\n","from text_processing import *"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFayi-JvrDHx","executionInfo":{"status":"ok","timestamp":1631164990865,"user_tz":420,"elapsed":765,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"5ae8dd51-f954-4c8e-da6f-159617c8b8a5"},"source":["# Enable GPU before proceeding\n","device_name = tf.test.gpu_device_name()\n","print(\"Device found:\", device_name)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Device found: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLkb-vZhryC-","executionInfo":{"status":"ok","timestamp":1631164990866,"user_tz":420,"elapsed":15,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"836edddb-9c8d-46e1-bcd2-e94ce5a22bd3"},"source":["# Test if CUDA is available, use it\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(\"Using CUDA Device:\", torch.cuda.get_device_name())"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Using CUDA Device: Tesla K80\n"]}]},{"cell_type":"markdown","metadata":{"id":"Jgmig-gyT5_U"},"source":["# DOWNLOAD AND PREPROCESS DATA"]},{"cell_type":"code","metadata":{"id":"dJ7PFVKhT_2S","colab":{"base_uri":"https://localhost:8080/","height":930},"executionInfo":{"status":"ok","timestamp":1631164990868,"user_tz":420,"elapsed":13,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"610b2cbd-0f5d-4b04-fe84-6a238b3d2717"},"source":["vid = pd.read_csv(PATH_PREFIX + '/Data/vidgen_final_data.csv', \n","                   dtype={'tweetid':str, 'label':int, 'aggr':int, 'target':int})\n","\n","vid = vid.sample(frac=1, random_state=123)\n","\n","vid['target'] = 0 \n","vid.loc[vid.label != 0, 'target'] = 1\n","\n","vid.sample(2)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>annot1</th>\n","      <th>annot2</th>\n","      <th>content</th>\n","      <th>expert</th>\n","      <th>label</th>\n","      <th>orig_final_label</th>\n","      <th>text</th>\n","      <th>tweetid</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1831</th>\n","      <td>1831</td>\n","      <td>entity_directed_hostility</td>\n","      <td>entity_directed_hostility</td>\n","      <td>@SCMPNews Itâ€™s hard for HK and the rest of the world to move forward with mainlander communists running China. Reneging on promised democracy caused the protests and then the #ChinaVirus spread to the entire globe. #China is ðŸ’¯ responsible for everything.</td>\n","      <td>entity_directed_hostility</td>\n","      <td>2</td>\n","      <td>entity_directed_hostility</td>\n","      <td>&lt;user&gt; its hard for hk and the rest of the world to move forward with mainlander communists running china. reneging on promised democracy caused the protests and then the chinavirus spread to the entire globe. china is responsible for everything.</td>\n","      <td>1234699390847029248</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2402</th>\n","      <td>2402</td>\n","      <td>entity_directed_criticism</td>\n","      <td>entity_directed_hostility</td>\n","      <td>@jtbrg 1. how come asking question to dictator establishment of china is racist 2. virus originated in china. the establishment hide the information and punished the whistle blowers. government number are fake.  3. no one believes in fake conspiracy theory #chinacoronavirus #chinalies</td>\n","      <td>entity_directed_criticism</td>\n","      <td>1</td>\n","      <td>entity_directed_criticism</td>\n","      <td>&lt;user&gt; 1. how come asking question to dictator establishment of china is racist 2. virus originated in china. the establishment hide the information and punished the whistle blowers. government number are fake. 3. no one believes in fake conspiracy theory china coronavirus china lies</td>\n","      <td>1239373282861711360</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Unnamed: 0                     annot1  ...              tweetid target\n","1831        1831  entity_directed_hostility  ...  1234699390847029248      1\n","2402        2402  entity_directed_criticism  ...  1239373282861711360      1\n","\n","[2 rows x 10 columns]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5C_JQRxRz2p-","executionInfo":{"status":"ok","timestamp":1631164991023,"user_tz":420,"elapsed":164,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"60ca6cf9-3b41-4b78-b5e5-71dd2ccb2539"},"source":["train_her = vid[:2400]\n","test_her = vid[2400:]\n","\n","# oversample absusive class in train \n","# Oversample abusive\n","# train_her = pd.concat([train_her, train_her[train_her.label == 1], train_her[train_her.label == 1]], axis=0, ignore_index=True).sample(frac=1)\n","train_her.groupby('label').label.count()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["label\n","0    800\n","1    795\n","2    805\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0gyr7Hi_7T61","executionInfo":{"status":"ok","timestamp":1631164991024,"user_tz":420,"elapsed":7,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"e547d9c1-1ffd-42b4-9cf7-e5a0c4957e0c"},"source":["train_her.groupby('target').label.count()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["target\n","0     800\n","1    1600\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"42nIFpyRNTJw"},"source":["## Tokenize state"]},{"cell_type":"code","metadata":{"id":"GPIccBVB_yr1","executionInfo":{"status":"ok","timestamp":1631164991152,"user_tz":420,"elapsed":132,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["# import hashtag_dict \n","HASHTAG_DIR = '/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech/utils/' \n","with open(HASHTAG_DIR + 'hashtag_dict.json', 'r') as f:\n","    hashtag_dict = json.load(f)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"LAKmvo4aZVFv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631164991153,"user_tz":420,"elapsed":8,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"ed98c84a-7548-436e-938e-3a0c3bf84927"},"source":["# CUDA is memory hungry. Needs to reduce the max_len\n","MAX_LEN = 225\n","print(\"Maximum length of cleaned up dataset is:\", MAX_LEN)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum length of cleaned up dataset is: 225\n"]}]},{"cell_type":"code","metadata":{"id":"CIPViSOuXhTA","executionInfo":{"status":"ok","timestamp":1631164992397,"user_tz":420,"elapsed":1247,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HP_qSMkuohrO","executionInfo":{"status":"ok","timestamp":1631164994471,"user_tz":420,"elapsed":2078,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"a1f0ccff-2e83-452b-ed0f-0490cf0a8e7f"},"source":["train_input_ids, train_attn_masks  = tokenizing(train_her.text.values, tokenizer, MAX_LEN)\n","test_input_ids, test_attn_masks  = tokenizing(test_her.text.values, tokenizer, MAX_LEN)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Total time taken:  1.6572070121765137\n","Total time taken:  0.3567667007446289\n"]}]},{"cell_type":"code","metadata":{"id":"QTmGsPduAY9n","executionInfo":{"status":"ok","timestamp":1631164994633,"user_tz":420,"elapsed":166,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["train_labels = [train_her.label.values, train_her.target.values ]\n","train_tensor = prepare_tensorset(train_input_ids, train_attn_masks, train_labels)\n","\n","test_labels = [test_her.label.values, test_her.target.values]\n","test_tensor = prepare_tensorset(test_input_ids, test_attn_masks, test_labels)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jKEuQnyKzKaP"},"source":["# BUILD MODEL"]},{"cell_type":"markdown","metadata":{"id":"ptpLoOHEKWBx"},"source":["In this model, we will build an LSTM model leveraging BERT base hidden data on top. The key difference compared to simpleBert is that we need to save the parameters."]},{"cell_type":"code","metadata":{"id":"t0NtCmP8NM8B","executionInfo":{"status":"ok","timestamp":1631164994634,"user_tz":420,"elapsed":6,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["SAVE_PATH = \"/content/drive/My Drive/Colab Notebooks/Bert Hate Speech/Saved Parameters/Vidgen/Target\""],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YNwxALuZR-eE"},"source":["## RUN MODEL WITH DIFFERENT SEEDS\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"xzC7Y5OJYnQF","executionInfo":{"status":"ok","timestamp":1631164994634,"user_tz":420,"elapsed":5,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["def run_models(save_path:str, model_class, num_labels, num_tasks, max_len,\n","        num_epochs, loss_funcs:list, device,\n","        train_tensor, test_tensor, val_tensor=None, batch_size=20, label_ls = [[0,1,2]],\n","        seed_list = [101,211,307,401,503], save_seed=0):\n","\n","    final_metrics = dict()\n","    # Iterate through seeds\n","    for idx, s in enumerate(seed_list):\n","        print('========== Trying seed', s, '==========')\n","        # Reset the seed\n","        seed = s\n","        random.seed(seed)\n","        os.environ['PYTHONHASHSEED'] = str(seed)\n","        np.random.seed(seed)\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = True\n","    \n","        # print(\"Random num: \", random.randint(1,1000))\n","        \n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","        # Initialize model\n","        model = model_class('roberta-base', num_labels=num_labels, max_len=max_len)\n","        optimizer = AdamW(model.parameters(),lr=2e-5, eps=1e-6, weight_decay=1e-3)\n","        build_params = {'device':device, 'optimizer': optimizer, 'loss_functions': loss_funcs}\n","        # build \n","        model.build(**build_params)\n","\n","        # train\n","        if val_tensor is None:\n","            model.train(train_tensor, batch_size = batch_size,\n","                        num_epochs=num_epochs, verbose=True)\n","        else: \n","            model.train(train_tensor, val_tensor=val_tensor, batch_size=batch_size,\n","                        num_epochs=num_epochs, verbose=True)\n","\n","        # evaluate\n","        _, logits, labels = model.evaluate(test_tensor)\n","        logits, labels = format_outputs(logits, labels, num_tasks)\n","        preds = get_labels_from_multi_logits(logits)\n","        res = print_report_multitask(labels, preds, label_ls )\n","\n","        final_metrics[s] = res\n","\n","        if idx==save_seed:\n","            model.save(save_path)\n","        del model\n","\n","    return final_metrics "],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"8v4xghBGacRw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631165928765,"user_tz":420,"elapsed":934136,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"20a4f891-3c98-41ff-a99e-5ff4877dbdda"},"source":["model_class = RobertaLSTM\n","num_labels =  [3,4]\n","num_tasks = len(num_labels)\n","label_ls = [[0,1,2], [0,1,2,3]]\n","num_epochs = 5\n","loss_funcs = [CrossEntropyLoss()] * num_tasks\n","\n","model_params = {'num_labels':num_labels, 'num_tasks':num_tasks, \n","                'max_len':MAX_LEN,'label_ls':label_ls,\n","                'num_epochs':num_epochs, 'loss_funcs':loss_funcs,\n","                }\n","\n","results = run_models(save_path = SAVE_PATH, model_class=model_class, device=device, \n","     train_tensor=train_tensor, test_tensor=test_tensor, seed_list=[123],\n","      **model_params )"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["========== Trying seed 123 ==========\n","Multitask training: 2 tasks \n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Multitask training: 2 tasks \n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Running Epoch  0\n","Training loss : [109.50541365146637, 63.63934049755335]. Validation loss: []. Duration: 181.96240758895874\n","Running Epoch  1\n","Training loss : [82.06069928407669, 36.44723783433437]. Validation loss: []. Duration: 181.62527894973755\n","Running Epoch  2\n","Training loss : [66.68619553744793, 26.959451699629426]. Validation loss: []. Duration: 181.72063040733337\n","Running Epoch  3\n","Training loss : [49.71630299091339, 16.5498999459669]. Validation loss: []. Duration: 181.57637286186218\n","Running Epoch  4\n","Training loss : [39.32869906537235, 10.36335992696695]. Validation loss: []. Duration: 181.7084813117981\n","num_tasks 2\n","\n","-----Report for task 0:-----\n","\n","precision: [0.84263959 0.648      0.73202614]\n","recall   : [0.83       0.7902439  0.57435897]\n","fscore   : [0.83627204 0.71208791 0.64367816]\n","support  : [200 205 195]\n","\n","-----Report for task 1:-----\n","\n","precision: [0.85128205 0.91604938 0.         0.        ]\n","recall   : [0.83   0.9275 0.     0.    ]\n","fscore   : [0.84050633 0.92173913 0.         0.        ]\n","support  : [200 400   0   0]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vfnEBUbZqBuk","executionInfo":{"status":"ok","timestamp":1631165928771,"user_tz":420,"elapsed":22,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"a71dd5df-21c0-404c-a65b-070a3e99425a"},"source":["results[123][0]['macro_metrics']"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7408885792331596, 0.7315342922659994, 0.7306793711032399]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":134},"id":"Aa0E43BbaPrL","executionInfo":{"status":"ok","timestamp":1631165928772,"user_tz":420,"elapsed":15,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"e72d2b5a-7f04-4a79-f0d4-941ac61d9277"},"source":["macro_res    = get_macro_results(results,task_no=1)\n","macro_res"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.74 +- 0.0</td>\n","      <td>0.73 +- 0.0</td>\n","      <td>0.74 +- 0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             0            1            2\n","0  0.74 +- 0.0  0.73 +- 0.0  0.74 +- 0.0"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"HPpGBDuFRMcl","executionInfo":{"status":"ok","timestamp":1631165928955,"user_tz":420,"elapsed":194,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":[""],"execution_count":21,"outputs":[]}]}