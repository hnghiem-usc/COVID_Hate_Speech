{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RoBerta_LSTM_Founta_analysis","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b47b8a604e1e4bcbba436839150683e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_56c4485b86ba40c29166ddab1cb5565d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f25b74eb112e47f8ab497902d7e5fa3c","IPY_MODEL_0a629fe76bc24a0a89114fee9cdd669c","IPY_MODEL_dc4493ddcb674ff68fa1de53c8d93929"]}},"56c4485b86ba40c29166ddab1cb5565d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f25b74eb112e47f8ab497902d7e5fa3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_40711677decb477caef30610c8a21bb9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_54b04137290945599d4a6abfcb094d2b"}},"0a629fe76bc24a0a89114fee9cdd669c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6f48ececf5594fe58e9cf6d6eaf7cced","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e048644bf06a4090a823d8aea272e119"}},"dc4493ddcb674ff68fa1de53c8d93929":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4359aee635784b47bf7cb029068f829f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:00&lt;00:00, 969kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_708a1365f1274d09b04ffb0db7dafe0a"}},"40711677decb477caef30610c8a21bb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"54b04137290945599d4a6abfcb094d2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f48ececf5594fe58e9cf6d6eaf7cced":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e048644bf06a4090a823d8aea272e119":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4359aee635784b47bf7cb029068f829f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"708a1365f1274d09b04ffb0db7dafe0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c1bb1fa346340369c64184d44073a4e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_37b591a9d5354e0489d3d3f2ed783650","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_65ab38c49f574b25a14f2c808aa7aa37","IPY_MODEL_65261735f9b543ce877eb59970130436","IPY_MODEL_8b9f611832d5491b8e2f5225a6d39225"]}},"37b591a9d5354e0489d3d3f2ed783650":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"65ab38c49f574b25a14f2c808aa7aa37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_df59db0ee1fc427a95388d3f5b3a0008","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe18e4f73ec94e079dbdad303cbd834f"}},"65261735f9b543ce877eb59970130436":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2887a75468bc4ada9aac6935ec873de2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5cdfcef1a30b4b3092c336ba0a3e5778"}},"8b9f611832d5491b8e2f5225a6d39225":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b1fcbca211bd4801b34e4dd2ab17b5a7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 971kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0dfc92d2092343fa9fd19b3e2b09ae4a"}},"df59db0ee1fc427a95388d3f5b3a0008":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fe18e4f73ec94e079dbdad303cbd834f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2887a75468bc4ada9aac6935ec873de2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5cdfcef1a30b4b3092c336ba0a3e5778":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b1fcbca211bd4801b34e4dd2ab17b5a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0dfc92d2092343fa9fd19b3e2b09ae4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3913d9e77d5456aaa670c822e31e97b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_14c5b22add4c45f9867f22e492e5067e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3d60c6d401674b2cb0597e3bb847d43e","IPY_MODEL_5ff044a79c074df89a3438ef91dbc487","IPY_MODEL_da79c1c72e2d47ee9aa0a7a03ce47148"]}},"14c5b22add4c45f9867f22e492e5067e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d60c6d401674b2cb0597e3bb847d43e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6dc37352cac74132b71b83f873237108","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1000a46ec51d48f79699e356189a8275"}},"5ff044a79c074df89a3438ef91dbc487":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_778154dd42154536a45d3bb1761d858a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e31478914e72442ea0ff15d6002b388e"}},"da79c1c72e2d47ee9aa0a7a03ce47148":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7a5a9a5b906a4d2484ce094490355318","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:00&lt;00:00, 3.72MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f1fc155bec5647ca91fa9594015d8dcb"}},"6dc37352cac74132b71b83f873237108":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1000a46ec51d48f79699e356189a8275":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"778154dd42154536a45d3bb1761d858a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e31478914e72442ea0ff15d6002b388e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a5a9a5b906a4d2484ce094490355318":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f1fc155bec5647ca91fa9594015d8dcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a9ef00df32894157a179e5ca71c839bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e31762aae3244c0db1cbc2a523f0f2d3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f845b933b5fb462cb2f7a0fee4a798d6","IPY_MODEL_7ff4442728fb4bfaab1a77440d587287","IPY_MODEL_b8119e823f0e4115b426c85bedd341aa"]}},"e31762aae3244c0db1cbc2a523f0f2d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f845b933b5fb462cb2f7a0fee4a798d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dded66a2f0e04744b2c5ee38a9929add","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3be4fbc486c2410b9b076443feff4dda"}},"7ff4442728fb4bfaab1a77440d587287":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f0279b995e51407eae64e84621b92d6e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":481,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":481,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e78fec6244247d9a8d91295d94a4011"}},"b8119e823f0e4115b426c85bedd341aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c042402cf8db439992fcfcfdfef18839","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 481/481 [00:00&lt;00:00, 12.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_60a67ae6200c4fedaa3f445ec47285f8"}},"dded66a2f0e04744b2c5ee38a9929add":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3be4fbc486c2410b9b076443feff4dda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0279b995e51407eae64e84621b92d6e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7e78fec6244247d9a8d91295d94a4011":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c042402cf8db439992fcfcfdfef18839":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"60a67ae6200c4fedaa3f445ec47285f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f42c115f8f7a4c6bba10b95d7f91c697":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6e05372d23fb4d54bf86070c80c3ae0f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_95b6aedf09ba45d68ff3802e4f216a97","IPY_MODEL_7af6f6a27c4e43e9adc9dcee38fcef97","IPY_MODEL_706d4859493d44ceb097f4441179875a"]}},"6e05372d23fb4d54bf86070c80c3ae0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95b6aedf09ba45d68ff3802e4f216a97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_64a160994342460d96bb39b077c18126","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b24a1b5b3a0f499eb4179f47e51c1cde"}},"7af6f6a27c4e43e9adc9dcee38fcef97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_676659c69b744c8388bd0b558ab30e30","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":501200538,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":501200538,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac4698570a6f465b8cdaa98f68fd200d"}},"706d4859493d44ceb097f4441179875a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_26096d3af19949b59d8c1ea3a40dc463","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 501M/501M [00:10&lt;00:00, 48.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_18a1f775f2c2486188a541ad4db6a548"}},"64a160994342460d96bb39b077c18126":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b24a1b5b3a0f499eb4179f47e51c1cde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"676659c69b744c8388bd0b558ab30e30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ac4698570a6f465b8cdaa98f68fd200d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26096d3af19949b59d8c1ea3a40dc463":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"18a1f775f2c2486188a541ad4db6a548":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pp3_2ZLq6NS","executionInfo":{"status":"ok","timestamp":1631407250206,"user_tz":420,"elapsed":5012,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"7588a2d6-e874-4502-aa76-5b55502fb3d9"},"source":["from datetime import datetime\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import re, string\n","import time\n","import random\n","import gc\n","import os, sys\n","import json\n","from copy import deepcopy\n","\n","#####\n","# !pip install gdown\n","!pip install transformers\n","pd.options.display.max_colwidth = 500\n","#####\n","\n","import torch\n","\n","from transformers import BertForSequenceClassification, AdamW , BertConfig, BertModel\n","from transformers import RobertaConfig, RobertaModel, RobertaTokenizer, RobertaForSequenceClassification\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import LineByLineTextDataset\n","\n","from torch.nn import LSTM, Dropout, Linear, BCELoss, CrossEntropyLoss, Softmax, ReLU, LeakyReLU, Tanh\n","from torch.nn.functional import softmax, relu\n","from torch.nn.utils.rnn import pack_padded_sequence\n","from torch.utils.data.dataset import Subset\n","\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n","\n","seed = 401\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = True\n","\n","%load_ext autoreload \n","%autoreload 2"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.2)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzEvkGACWMqX","executionInfo":{"status":"ok","timestamp":1631407250208,"user_tz":420,"elapsed":23,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"731bb355-92a5-4dd8-fdd6-983b8ed33190"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUYifLXWu1D0","executionInfo":{"status":"ok","timestamp":1631407250377,"user_tz":420,"elapsed":186,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"e233987b-f370-4d22-8271-1e8f6e684a8d"},"source":["!ls \"/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech/Model\""],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["'Bert Models'   models.py   __pycache__   RoBerta  'Roberta Final'\n"]}]},{"cell_type":"code","metadata":{"id":"f6srHxsX4FhM","executionInfo":{"status":"ok","timestamp":1631407250378,"user_tz":420,"elapsed":5,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}}},"source":["PATH_PREFIX = '/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"C8keHP8s6Fj4","executionInfo":{"status":"ok","timestamp":1631407251022,"user_tz":420,"elapsed":648,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}}},"source":["sys.path.append('/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech/utils')\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech/Model')\n","\n","from models import *\n","from text_processing import *"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFayi-JvrDHx","executionInfo":{"status":"ok","timestamp":1631407251640,"user_tz":420,"elapsed":622,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"10666029-2f87-44b9-c0e5-124997da127d"},"source":["# Enable GPU before proceeding\n","device_name = tf.test.gpu_device_name()\n","print(\"Device found:\", device_name)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Device found: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLkb-vZhryC-","executionInfo":{"status":"ok","timestamp":1631407251641,"user_tz":420,"elapsed":10,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"a9050ef2-d992-4c36-a7b5-6136d9e237ab"},"source":["# Test if CUDA is available, use it\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(\"Using CUDA Device:\", torch.cuda.get_device_name())"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Using CUDA Device: Tesla T4\n"]}]},{"cell_type":"markdown","metadata":{"id":"Jgmig-gyT5_U"},"source":["# DOWNLOAD AND PREPROCESS DATA"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TIGMfizwRlrM","executionInfo":{"status":"ok","timestamp":1631407252362,"user_tz":420,"elapsed":726,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"2a94c7a2-b719-4ad7-958c-201136a2e3d2"},"source":["train_dt, test_dt = load_data(PATH_PREFIX + '/Data/HER_final_data.csv', \n","                   dtype_dict={'tweetid':str, 'label':int, 'target':int, 'aggr':int})"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["label\n","0    1894\n","1     304\n","2     202\n","Name: label, dtype: int64\n","target\n","0    2003\n","1     367\n","2      25\n","3       5\n","Name: target, dtype: int64\n","aggr\n","0    1799\n","1     533\n","2      68\n","Name: aggr, dtype: int64\n"]}]},{"cell_type":"markdown","metadata":{"id":"42nIFpyRNTJw"},"source":["## Tokenize state"]},{"cell_type":"code","metadata":{"id":"GPIccBVB_yr1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631407252569,"user_tz":420,"elapsed":210,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"ac5e69eb-64fb-416a-f7c8-f487ddba345c"},"source":["# import hashtag_dict \n","HASHTAG_DIR = '/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech/utils/' \n","with open(HASHTAG_DIR + 'hashtag_dict.json', 'r') as f:\n","    hashtag_dict = json.load(f)\n","\n","# CUDA is memory hungry. Needs to reduce the max_len\n","MAX_LEN = 225\n","print(\"Maximum length of cleaned up dataset is:\", MAX_LEN)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum length of cleaned up dataset is: 225\n"]}]},{"cell_type":"code","metadata":{"id":"CIPViSOuXhTA","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["b47b8a604e1e4bcbba436839150683e8","56c4485b86ba40c29166ddab1cb5565d","f25b74eb112e47f8ab497902d7e5fa3c","0a629fe76bc24a0a89114fee9cdd669c","dc4493ddcb674ff68fa1de53c8d93929","40711677decb477caef30610c8a21bb9","54b04137290945599d4a6abfcb094d2b","6f48ececf5594fe58e9cf6d6eaf7cced","e048644bf06a4090a823d8aea272e119","4359aee635784b47bf7cb029068f829f","708a1365f1274d09b04ffb0db7dafe0a","5c1bb1fa346340369c64184d44073a4e","37b591a9d5354e0489d3d3f2ed783650","65ab38c49f574b25a14f2c808aa7aa37","65261735f9b543ce877eb59970130436","8b9f611832d5491b8e2f5225a6d39225","df59db0ee1fc427a95388d3f5b3a0008","fe18e4f73ec94e079dbdad303cbd834f","2887a75468bc4ada9aac6935ec873de2","5cdfcef1a30b4b3092c336ba0a3e5778","b1fcbca211bd4801b34e4dd2ab17b5a7","0dfc92d2092343fa9fd19b3e2b09ae4a","e3913d9e77d5456aaa670c822e31e97b","14c5b22add4c45f9867f22e492e5067e","3d60c6d401674b2cb0597e3bb847d43e","5ff044a79c074df89a3438ef91dbc487","da79c1c72e2d47ee9aa0a7a03ce47148","6dc37352cac74132b71b83f873237108","1000a46ec51d48f79699e356189a8275","778154dd42154536a45d3bb1761d858a","e31478914e72442ea0ff15d6002b388e","7a5a9a5b906a4d2484ce094490355318","f1fc155bec5647ca91fa9594015d8dcb","a9ef00df32894157a179e5ca71c839bf","e31762aae3244c0db1cbc2a523f0f2d3","f845b933b5fb462cb2f7a0fee4a798d6","7ff4442728fb4bfaab1a77440d587287","b8119e823f0e4115b426c85bedd341aa","dded66a2f0e04744b2c5ee38a9929add","3be4fbc486c2410b9b076443feff4dda","f0279b995e51407eae64e84621b92d6e","7e78fec6244247d9a8d91295d94a4011","c042402cf8db439992fcfcfdfef18839","60a67ae6200c4fedaa3f445ec47285f8"]},"executionInfo":{"status":"ok","timestamp":1631407257420,"user_tz":420,"elapsed":4854,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"180338ad-a9ab-4e9b-cdd7-5195fd4e68ab"},"source":["tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b47b8a604e1e4bcbba436839150683e8","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c1bb1fa346340369c64184d44073a4e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3913d9e77d5456aaa670c822e31e97b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9ef00df32894157a179e5ca71c839bf","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HP_qSMkuohrO","executionInfo":{"status":"ok","timestamp":1631407258985,"user_tz":420,"elapsed":1580,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"037c140c-7c2a-4465-f97d-888a68a4b667"},"source":["train_input_ids, train_attn_masks  = tokenizing(train_dt.text.values, tokenizer, MAX_LEN)\n","test_input_ids, test_attn_masks  = tokenizing(test_dt.text.values, tokenizer, MAX_LEN)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Total time taken:  1.3307445049285889\n","Total time taken:  0.30443382263183594\n"]}]},{"cell_type":"code","metadata":{"id":"5UaN8FNEUbn9","executionInfo":{"status":"ok","timestamp":1631407259195,"user_tz":420,"elapsed":214,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}}},"source":["varlist = ['label']\n","_, train_tensor = arrange_tensor(train_dt, train_input_ids, train_attn_masks ,varlist=varlist)\n","_, test_tensor  = arrange_tensor(test_dt, test_input_ids, test_attn_masks ,varlist=varlist)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RNJyuEsVfCB","executionInfo":{"status":"ok","timestamp":1631407259196,"user_tz":420,"elapsed":10,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"6920ef1f-bfd4-4e21-f8cc-6ee6e0e01807"},"source":["test_tensor[:][-1].shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([600])"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"jKEuQnyKzKaP"},"source":["# BUILD MODEL"]},{"cell_type":"markdown","metadata":{"id":"ptpLoOHEKWBx"},"source":["In this model, we will build an LSTM model leveraging BERT base hidden data on top. The key difference compared to simpleBert is that we need to save the parameters."]},{"cell_type":"code","metadata":{"id":"t0NtCmP8NM8B","executionInfo":{"status":"ok","timestamp":1631407259338,"user_tz":420,"elapsed":147,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}}},"source":["SAVE_PATH = \"/content/drive/My Drive/Colab Notebooks/Bert Hate Speech/Saved Parameters/\""],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nTFb-MmerbQ6"},"source":[""]},{"cell_type":"code","metadata":{"id":"15EW5Jz3HNU-","executionInfo":{"status":"ok","timestamp":1631407259338,"user_tz":420,"elapsed":4,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}}},"source":["##### load the correct weights########\n","TRANSFER_DIR = \"/content/drive/My Drive/Colab Notebooks/Bert Hate Speech/Saved Parameters/Founta/\""],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_iTm811coQuf","executionInfo":{"status":"ok","timestamp":1631407259724,"user_tz":420,"elapsed":389,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"eb79bba6-4b4c-4bc5-b8ec-7fa62055b088"},"source":["###### !!CHECK THIS!! ######\n","model_class = RobertaLSTM\n","model_str = 'Roberta_LSTM'\n","###########################\n","for filename in os.listdir(TRANSFER_DIR):\n","    if model_str  in filename:\n","        # pick the first file\n","        transfer_weights = TRANSFER_DIR + filename\n","        print(\"Transferring weights from :\", transfer_weights)\n","        break"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Transferring weights from : /content/drive/My Drive/Colab Notebooks/Bert Hate Speech/Saved Parameters/Founta/Roberta_LSTM_09_07_21_2203.pth\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409,"referenced_widgets":["f42c115f8f7a4c6bba10b95d7f91c697","6e05372d23fb4d54bf86070c80c3ae0f","95b6aedf09ba45d68ff3802e4f216a97","7af6f6a27c4e43e9adc9dcee38fcef97","706d4859493d44ceb097f4441179875a","64a160994342460d96bb39b077c18126","b24a1b5b3a0f499eb4179f47e51c1cde","676659c69b744c8388bd0b558ab30e30","ac4698570a6f465b8cdaa98f68fd200d","26096d3af19949b59d8c1ea3a40dc463","18a1f775f2c2486188a541ad4db6a548"]},"id":"W10NDfiEIa6S","executionInfo":{"status":"ok","timestamp":1631407288170,"user_tz":420,"elapsed":28449,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"13059a63-8fa5-40a9-8cb9-56e0ce8afc29"},"source":["target_ls = ['label']\n","num_labels =  [3]\n","num_tasks = len(num_labels)\n","label_ls = [[0,1,2]]\n","num_epochs = 3\n","max_len = 225\n","\n","# change correct weights\n","loss_funcs = [CrossEntropyLoss()] * num_tasks\n","\n","model = model_class('roberta-base', num_labels=num_labels, max_len=max_len)\n","# load transfer weights:\n","if transfer_weights is not None:\n","    base_model = model_class.load(transfer_weights)\n","    model.load_states(base_model.device_objects)\n","\n","optimizer = AdamW(model.parameters(),lr=2e-5, eps=1e-6, weight_decay=1e-3)\n","build_params = {'device':device, 'optimizer': optimizer, 'loss_functions': loss_funcs}\n","# build \n","model.build(**build_params)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Sigle-task training\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f42c115f8f7a4c6bba10b95d7f91c697","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Single-task training\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Sigle-task training\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Single-task training\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Loading state_dict for self.bert\n","Loading state_dict for self.dropout\n","Loading state_dict for self.lstm\n","Loading state_dict for self.fc0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JOXCzdToCuB","executionInfo":{"status":"ok","timestamp":1631407296686,"user_tz":420,"elapsed":8535,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"3ce5615d-d193-4b43-ac86-bd711ed136f8"},"source":[" # evaluate\n","_, logits, labels = model.evaluate(test_tensor)\n","logits, labels = format_outputs(logits, labels, num_tasks)\n","preds = get_labels_from_multi_logits(logits)\n","res = print_report_multitask(labels, preds, label_ls )\n","\n"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["num_tasks 1\n","\n","-----Report for task 0:-----\n","\n","precision: [0.88753056 0.23076923 0.07865169]\n","recall   : [0.74845361 0.03846154 0.37837838]\n","fscore   : [0.81208054 0.06593407 0.13023256]\n","support  : [485  78  37]\n"]}]},{"cell_type":"code","metadata":{"id":"8H3mmM5zMY5v","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1631407296688,"user_tz":420,"elapsed":25,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"34637e5a-ea8a-4010-bb0f-680a1f0116f2"},"source":["cm = pd.DataFrame(confusion_matrix(labels[0],  preds[0]), columns = ['Normal', 'Abusive', 'Hate'])\n","cm.index = ['Normal', 'Abusive', 'Hate']\n","cm"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Normal</th>\n","      <th>Abusive</th>\n","      <th>Hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Normal</th>\n","      <td>363</td>\n","      <td>9</td>\n","      <td>113</td>\n","    </tr>\n","    <tr>\n","      <th>Abusive</th>\n","      <td>24</td>\n","      <td>3</td>\n","      <td>51</td>\n","    </tr>\n","    <tr>\n","      <th>Hate</th>\n","      <td>22</td>\n","      <td>1</td>\n","      <td>14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Normal  Abusive  Hate\n","Normal      363        9   113\n","Abusive      24        3    51\n","Hate         22        1    14"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDav5b8WqMEW","executionInfo":{"status":"ok","timestamp":1631407296865,"user_tz":420,"elapsed":199,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"bea4041c-a305-48f3-ddb2-3a4e3536023e"},"source":["# the array is of the right order\n","np.all(test_dt.label.values == np.array(labels[0]))"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"BH8dJnPLrosM"},"source":["## FOR LSTM MODEL"]},{"cell_type":"code","metadata":{"id":"Tml0CX1CxF3G","executionInfo":{"status":"ok","timestamp":1631407296866,"user_tz":420,"elapsed":7,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}}},"source":["del model"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"QNDhl206rxoA","executionInfo":{"status":"ok","timestamp":1631407296867,"user_tz":420,"elapsed":7,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"16adf344-d8a9-47c9-cc77-a6f02a50fd02"},"source":["LSTM_PATH = SAVE_PATH + '/Roberta/Roberta_LSTM_seed_401.pth'\n","LSTM_PATH"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Bert Hate Speech/Saved Parameters//Roberta/Roberta_LSTM_seed_401.pth'"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R1WEcnOfwmmr","executionInfo":{"status":"ok","timestamp":1631407297970,"user_tz":420,"elapsed":1109,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"cd18c4f5-1009-49be-d25a-e65c2eb65b87"},"source":["train_input_ids, train_attn_masks  = tokenizing(train_dt.text.values, tokenizer, MAX_LEN)\n","test_input_ids, test_attn_masks  = tokenizing(test_dt.text.values, tokenizer, MAX_LEN)\n","\n","varlist = ['label','target','aggr']\n","\n","_, train_tensor = arrange_tensor(train_dt, train_input_ids, train_attn_masks ,varlist=varlist)\n","_, test_tensor  = arrange_tensor(test_dt, test_input_ids, test_attn_masks ,varlist=varlist)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Total time taken:  0.8358526229858398\n","Total time taken:  0.21564078330993652\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CCQFXTkCu_MS","executionInfo":{"status":"ok","timestamp":1631407307234,"user_tz":420,"elapsed":9268,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"486ce6f5-84a7-4921-c498-ba818e2563a3"},"source":["gc.collect\n","torch.cuda.empty_cache()\n","\n","target_ls = ['label','target','aggr']\n","num_labels =  [3,4,3]\n","num_tasks = len(num_labels)\n","label_ls = [[0,1,2],[0,1,2,3],[0,1,2]]\n","\n","# change correct weights\n","weight_dict = calculate_class_weights(train_dt, target_ls)\n","weight_ls  = [list(weight_dict[k].values()) for k in target_ls]\n","loss_funcs = [CrossEntropyLoss(weight=torch.tensor(w).to(device)) for w in weight_ls]\n","\n","model = model_class.load(LSTM_PATH)\n","\n","optimizer = AdamW(model.parameters(),lr=2e-5, eps=1e-6, weight_decay=1e-3)\n","build_params = {'device':device, 'optimizer': optimizer, 'loss_functions': loss_funcs}\n","# build \n","model.build(**build_params)\n"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Multitask training: 3 tasks \n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Multitask training: 3 tasks \n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v24uHLjtx3NZ","executionInfo":{"status":"ok","timestamp":1631407316140,"user_tz":420,"elapsed":8910,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"e152cc53-1004-4b24-e4ad-9a093761fd55"},"source":[" # evaluate\n","_, logits, labels = model.evaluate(test_tensor)\n","logits, labels = format_outputs(logits, labels, num_tasks)\n","preds = get_labels_from_multi_logits(logits)\n","res = print_report_multitask(labels, preds, label_ls )\n"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["num_tasks 3\n","\n","-----Report for task 0:-----\n","\n","precision: [0.93028322 0.484375   0.2987013 ]\n","recall   : [0.88041237 0.3974359  0.62162162]\n","fscore   : [0.90466102 0.43661972 0.40350877]\n","support  : [485  78  37]\n","\n","-----Report for task 1:-----\n","\n","precision: [0.96255507 0.59055118 0.21052632 0.        ]\n","recall   : [0.87051793 0.86206897 0.4        0.        ]\n","fscore   : [0.91422594 0.70093458 0.27586207 0.        ]\n","support  : [502  87  10   1]\n","\n","-----Report for task 2:-----\n","\n","precision: [0.89244851 0.59722222 0.36842105]\n","recall   : [0.88235294 0.62318841 0.35      ]\n","fscore   : [0.88737201 0.60992908 0.35897436]\n","support  : [442 138  20]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"1XwHvYuTyCeG","executionInfo":{"status":"ok","timestamp":1631407316141,"user_tz":420,"elapsed":19,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"46d3dc53-f9bf-41f0-c8a6-577c78e45088"},"source":["cm = pd.DataFrame(confusion_matrix(labels[0],  preds[0]), columns = ['Normal', 'Abusive', 'Hate'])\n","cm.index = ['Normal', 'Abusive', 'Hate']\n","cm"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Normal</th>\n","      <th>Abusive</th>\n","      <th>Hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Normal</th>\n","      <td>427</td>\n","      <td>28</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>Abusive</th>\n","      <td>23</td>\n","      <td>31</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>Hate</th>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>23</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Normal  Abusive  Hate\n","Normal      427       28    30\n","Abusive      23       31    24\n","Hate          9        5    23"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"1awSpP9czOJE"},"source":["## NOW TRY ON FOUNTA DATA"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KwZeuDLZlpT","executionInfo":{"status":"ok","timestamp":1631407316512,"user_tz":420,"elapsed":388,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"9416f453-449e-428d-f897-2ceedee343ff"},"source":["ft = pd.read_csv(PATH_PREFIX + '/Data/founta_final_data.csv', \n","                   dtype={'tweetid':str, 'label':int, 'aggr':int, 'target':int})\n","\n","ft = ft.sample(600, random_state=123)\n","ft.groupby('label').label.count()"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["label\n","0    198\n","1    202\n","2    200\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"OaXYJDK1aPcQ","executionInfo":{"status":"ok","timestamp":1631407316513,"user_tz":420,"elapsed":6,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}}},"source":["target_ls = ['label']\n","num_labels =  [3]\n","num_tasks = len(num_labels)\n","label_ls = [[0,1,2]]\n","num_epochs = 3\n","max_len = 225\n","\n","# change correct weights\n","loss_funcs = [CrossEntropyLoss()] * num_tasks\n","\n","optimizer = AdamW(model.parameters(),lr=2e-5, eps=1e-6, weight_decay=1e-3)\n","build_params = {'device':device, 'optimizer': optimizer, 'loss_functions': loss_funcs}"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JkxfB5jVaSb6","executionInfo":{"status":"ok","timestamp":1631407320238,"user_tz":420,"elapsed":3730,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"c8837afa-2d78-4ec0-9919-85afac368980"},"source":["new_model = RobertaLSTM('roberta-base', num_labels=num_labels, max_len=max_len)\n","new_model.load_states(model.device_objects)\n","# build \n","new_model.build(**build_params)"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Sigle-task training\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Single-task training\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Loading state_dict for self.bert\n","Loading state_dict for self.dropout\n","Loading state_dict for self.lstm\n","Loading state_dict for self.fc0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XcdthHRCc17l","executionInfo":{"status":"ok","timestamp":1631407320572,"user_tz":420,"elapsed":363,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"a40b5857-e259-4487-d606-ec64bdef1e7b"},"source":["test_input_ids, test_attn_masks  = tokenizing(ft.text.values, tokenizer, MAX_LEN)\n","varlist = ['label']\n","_, test_tensor  = arrange_tensor(ft, test_input_ids, test_attn_masks ,varlist=varlist)"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Total time taken:  0.2589719295501709\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qY51ryy_dpvb","executionInfo":{"status":"ok","timestamp":1631407329207,"user_tz":420,"elapsed":8640,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"09fd95a9-bfed-4ace-97bf-176142b953b3"},"source":[" # evaluate\n","_, logits, labels = new_model.evaluate(test_tensor)\n","logits, labels = format_outputs(logits, labels, num_tasks)\n","preds = get_labels_from_multi_logits(logits)\n","res = print_report_multitask(labels, preds, label_ls )"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["num_tasks 1\n","\n","-----Report for task 0:-----\n","\n","precision: [0.4822335  0.51456311 0.        ]\n","recall   : [0.95959596 0.52475248 0.        ]\n","fscore   : [0.64189189 0.51960784 0.        ]\n","support  : [198 202 200]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"yHLBhtWCd1NC","executionInfo":{"status":"ok","timestamp":1631407329209,"user_tz":420,"elapsed":22,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}},"outputId":"24bdaa62-5419-4923-d063-b7bffa27bc9f"},"source":["cm = pd.DataFrame(confusion_matrix(labels[0],  preds[0]), columns = ['Normal', 'Abusive', 'Hate'])\n","cm.index = ['Normal', 'Abusive', 'Hate']\n","cm"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Normal</th>\n","      <th>Abusive</th>\n","      <th>Hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Normal</th>\n","      <td>190</td>\n","      <td>8</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Abusive</th>\n","      <td>96</td>\n","      <td>106</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Hate</th>\n","      <td>108</td>\n","      <td>92</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Normal  Abusive  Hate\n","Normal      190        8     0\n","Abusive      96      106     0\n","Hate        108       92     0"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"mLFEbHqDeKnI","executionInfo":{"status":"ok","timestamp":1631407329211,"user_tz":420,"elapsed":21,"user":{"displayName":"Huy Nghiem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06903637911945605583"}}},"source":[""],"execution_count":32,"outputs":[]}]}