{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RoBerta_LSTM_Vidgen_aggr","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JXKj04qfZWOa","executionInfo":{"status":"ok","timestamp":1631169847597,"user_tz":420,"elapsed":198,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["# This module trains base on the Vidgen data with target against Asian."],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pp3_2ZLq6NS","executionInfo":{"status":"ok","timestamp":1631169854327,"user_tz":420,"elapsed":6634,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"694bd8ad-9abf-43c5-90a3-98e99c444eec"},"source":["from datetime import datetime\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import re, string\n","import time\n","import random\n","import gc\n","import os, sys\n","import json\n","from copy import deepcopy\n","\n","#####\n","# !pip install gdown\n","!pip install transformers\n","pd.options.display.max_colwidth = 500\n","#####\n","\n","import torch\n","##### SET SEEED ######\n","\n","######################\n","\n","# !pip install simpletransfomers\n","\n","from transformers import BertForSequenceClassification, AdamW , BertConfig, BertModel\n","from transformers import RobertaConfig, RobertaModel, RobertaTokenizer, RobertaForSequenceClassification\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import LineByLineTextDataset\n","\n","from torch.nn import LSTM, Dropout, Linear, BCELoss, CrossEntropyLoss, Softmax, ReLU, LeakyReLU, Tanh\n","from torch.nn.functional import softmax, relu\n","from torch.nn.utils.rnn import pack_padded_sequence\n","from torch.utils.data.dataset import Subset\n","\n","\n","\n","\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n","\n","%load_ext autoreload \n","%autoreload 2"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzEvkGACWMqX","executionInfo":{"status":"ok","timestamp":1631169854328,"user_tz":420,"elapsed":12,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"c4f4b59a-22ea-48d3-baca-3b8a7795827d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUYifLXWu1D0","executionInfo":{"status":"ok","timestamp":1631169854492,"user_tz":420,"elapsed":170,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"cafd0807-b586-4f1f-e8c0-d2bcaff40367"},"source":["!ls \"/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech/Model\""],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["'Bert Models'   models.py   __pycache__   RoBerta  'Roberta Final'\n"]}]},{"cell_type":"code","metadata":{"id":"f6srHxsX4FhM","executionInfo":{"status":"ok","timestamp":1631169854493,"user_tz":420,"elapsed":5,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["PATH_PREFIX = '/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"C8keHP8s6Fj4","executionInfo":{"status":"ok","timestamp":1631169855202,"user_tz":420,"elapsed":530,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["sys.path.append('/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech/utils')\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech/Model')\n","\n","from models import *\n","from text_processing import *"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFayi-JvrDHx","executionInfo":{"status":"ok","timestamp":1631169855985,"user_tz":420,"elapsed":785,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"00c2faa3-0c5c-4de2-c1d1-55f08be971cc"},"source":["# Enable GPU before proceeding\n","device_name = tf.test.gpu_device_name()\n","print(\"Device found:\", device_name)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Device found: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLkb-vZhryC-","executionInfo":{"status":"ok","timestamp":1631169855986,"user_tz":420,"elapsed":11,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"ff5e3ad9-d684-4774-c2f1-a0e7f8a91ec7"},"source":["# Test if CUDA is available, use it\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(\"Using CUDA Device:\", torch.cuda.get_device_name())"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Using CUDA Device: Tesla K80\n"]}]},{"cell_type":"markdown","metadata":{"id":"Jgmig-gyT5_U"},"source":["# DOWNLOAD AND PREPROCESS DATA"]},{"cell_type":"code","metadata":{"id":"dJ7PFVKhT_2S","colab":{"base_uri":"https://localhost:8080/","height":573},"executionInfo":{"status":"ok","timestamp":1631169855988,"user_tz":420,"elapsed":9,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"3bb52e26-255f-4c8d-91b8-f5b5442c530c"},"source":["vid = pd.read_csv(PATH_PREFIX + '/Data/vidgen_final_data.csv', \n","                   dtype={'tweetid':str, 'label':int, 'aggr':int, 'target':int})\n","\n","vid = vid.sample(frac=1, random_state=123)\n","\n","# map target\n","vid['target'] = 0 \n","vid.loc[vid.label != 0, 'target'] = 1\n","\n","#map aggr\n","vid['aggr'] = 0\n","vid.loc[vid.label == 1, 'aggr'] = 1\n","vid.loc[vid.label == 2, 'aggr'] = 2\n","\n","vid.sample(2)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>annot1</th>\n","      <th>annot2</th>\n","      <th>content</th>\n","      <th>expert</th>\n","      <th>label</th>\n","      <th>orig_final_label</th>\n","      <th>text</th>\n","      <th>tweetid</th>\n","      <th>target</th>\n","      <th>aggr</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>496</th>\n","      <td>496</td>\n","      <td>none_of_the_above</td>\n","      <td>none_of_the_above</td>\n","      <td>#WuFlu poll</td>\n","      <td>none_of_the_above</td>\n","      <td>0</td>\n","      <td>none_of_the_above</td>\n","      <td>wuflu poll</td>\n","      <td>1222328750932512768</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2574</th>\n","      <td>2574</td>\n","      <td>entity_directed_criticism</td>\n","      <td>none_of_the_above</td>\n","      <td>RT @germany_with_hk This is way too late.  There are so many people already left Wuhan or even the country, spreading the virus to the rest of the world  Please be alert!!!! Donâ€™t think you are not in Wuhan, then you would not be infected.  #WuhanCoronavirus  #ChinaPneumonia</td>\n","      <td>entity_directed_criticism</td>\n","      <td>1</td>\n","      <td>entity_directed_criticism</td>\n","      <td>&lt;user&gt; this is way too late. there are so many people already left wuhan or even the country, spreading the virus to the rest of the world please be alert!!!! dont think you are not in wuhan, then you would not be infected. wuhan coronavirus china pneumonia</td>\n","      <td>1220339894406410242</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Unnamed: 0                     annot1  ... target aggr\n","496          496          none_of_the_above  ...      0    0\n","2574        2574  entity_directed_criticism  ...      1    1\n","\n","[2 rows x 11 columns]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5C_JQRxRz2p-","executionInfo":{"status":"ok","timestamp":1631169856116,"user_tz":420,"elapsed":136,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"129b5ac2-0baa-49eb-9266-b8471eb7ce5a"},"source":["train_her = vid[:2400]\n","test_her = vid[2400:]\n","\n","# oversample absusive class in train \n","# Oversample abusive\n","# train_her = pd.concat([train_her, train_her[train_her.label == 1], train_her[train_her.label == 1]], axis=0, ignore_index=True).sample(frac=1)\n","train_her.groupby('label').label.count()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["label\n","0    800\n","1    795\n","2    805\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0gyr7Hi_7T61","executionInfo":{"status":"ok","timestamp":1631169856319,"user_tz":420,"elapsed":207,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"e4f41fe9-724a-4043-d21d-aab08991f520"},"source":["train_her.groupby('target').label.count()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["target\n","0     800\n","1    1600\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7rIgL-lZR--Z","executionInfo":{"status":"ok","timestamp":1631169856320,"user_tz":420,"elapsed":10,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"3c32339a-324e-43a7-ac93-b51bfe56e782"},"source":["train_her.groupby('aggr').label.count()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["aggr\n","0    800\n","1    795\n","2    805\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"42nIFpyRNTJw"},"source":["## Tokenize state"]},{"cell_type":"code","metadata":{"id":"GPIccBVB_yr1","executionInfo":{"status":"ok","timestamp":1631169856321,"user_tz":420,"elapsed":6,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["# import hashtag_dict \n","HASHTAG_DIR = '/content/drive/MyDrive/Colab Notebooks/Bert Hate Speech/utils/' \n","with open(HASHTAG_DIR + 'hashtag_dict.json', 'r') as f:\n","    hashtag_dict = json.load(f)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"LAKmvo4aZVFv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631169856482,"user_tz":420,"elapsed":166,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"529952d7-82ae-4754-d5bb-60aa10626c03"},"source":["# CUDA is memory hungry. Needs to reduce the max_len\n","MAX_LEN = 225\n","print(\"Maximum length of cleaned up dataset is:\", MAX_LEN)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum length of cleaned up dataset is: 225\n"]}]},{"cell_type":"code","metadata":{"id":"CIPViSOuXhTA","executionInfo":{"status":"ok","timestamp":1631169857947,"user_tz":420,"elapsed":1466,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HP_qSMkuohrO","executionInfo":{"status":"ok","timestamp":1631169860139,"user_tz":420,"elapsed":2199,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"d094560a-a79c-4a07-bf0b-4ef3590716a4"},"source":["train_input_ids, train_attn_masks  = tokenizing(train_her.text.values, tokenizer, MAX_LEN)\n","test_input_ids, test_attn_masks  = tokenizing(test_her.text.values, tokenizer, MAX_LEN)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Total time taken:  1.6624033451080322\n","Total time taken:  0.3760824203491211\n"]}]},{"cell_type":"code","metadata":{"id":"QTmGsPduAY9n","executionInfo":{"status":"ok","timestamp":1631169860140,"user_tz":420,"elapsed":11,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["train_labels = [train_her.label.values, train_her.target.values, train_her.aggr.values]\n","train_tensor = prepare_tensorset(train_input_ids, train_attn_masks, train_labels)\n","\n","test_labels = [test_her.label.values, test_her.target.values, test_her.aggr.values]\n","test_tensor = prepare_tensorset(test_input_ids, test_attn_masks, test_labels)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jKEuQnyKzKaP"},"source":["# BUILD MODEL"]},{"cell_type":"markdown","metadata":{"id":"ptpLoOHEKWBx"},"source":["In this model, we will build an LSTM model leveraging BERT base hidden data on top. The key difference compared to simpleBert is that we need to save the parameters."]},{"cell_type":"code","metadata":{"id":"t0NtCmP8NM8B","executionInfo":{"status":"ok","timestamp":1631169860140,"user_tz":420,"elapsed":10,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["SAVE_PATH = \"/content/drive/My Drive/Colab Notebooks/Bert Hate Speech/Saved Parameters/Vidgen/Aggr\""],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YNwxALuZR-eE"},"source":["## RUN MODEL WITH DIFFERENT SEEDS\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"xzC7Y5OJYnQF","executionInfo":{"status":"ok","timestamp":1631169860141,"user_tz":420,"elapsed":11,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["def run_models(save_path:str, model_class, num_labels, num_tasks, max_len,\n","        num_epochs, loss_funcs:list, device,\n","        train_tensor, test_tensor, val_tensor=None, batch_size=20, label_ls = [[0,1,2]],\n","        seed_list = [101,211,307,401,503], save_seed=0):\n","\n","    final_metrics = dict()\n","    # Iterate through seeds\n","    for idx, s in enumerate(seed_list):\n","        print('========== Trying seed', s, '==========')\n","        # Reset the seed\n","        seed = s\n","        random.seed(seed)\n","        os.environ['PYTHONHASHSEED'] = str(seed)\n","        np.random.seed(seed)\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = True\n","    \n","        # print(\"Random num: \", random.randint(1,1000))\n","        \n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","        # Initialize model\n","        model = model_class('roberta-base', num_labels=num_labels, max_len=max_len)\n","        optimizer = AdamW(model.parameters(),lr=2e-5, eps=1e-6, weight_decay=1e-3)\n","        build_params = {'device':device, 'optimizer': optimizer, 'loss_functions': loss_funcs}\n","        # build \n","        model.build(**build_params)\n","\n","        # train\n","        if val_tensor is None:\n","            model.train(train_tensor, batch_size = batch_size,\n","                        num_epochs=num_epochs, verbose=True)\n","        else: \n","            model.train(train_tensor, val_tensor=val_tensor, batch_size=batch_size,\n","                        num_epochs=num_epochs, verbose=True)\n","\n","        # evaluate\n","        _, logits, labels = model.evaluate(test_tensor)\n","        logits, labels = format_outputs(logits, labels, num_tasks)\n","        preds = get_labels_from_multi_logits(logits)\n","        res = print_report_multitask(labels, preds, label_ls )\n","\n","        final_metrics[s] = res\n","\n","        if idx==save_seed:\n","            model.save(save_path)\n","        del model\n","\n","    return final_metrics "],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"8v4xghBGacRw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631170792921,"user_tz":420,"elapsed":932791,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"f1600b7b-64db-4915-cfc6-c08f6b9ab5f8"},"source":["model_class = RobertaLSTM\n","num_labels =  [3,4,3]\n","num_tasks = len(num_labels)\n","label_ls = [[0,1,2], [0,1,2,3],[0,1,2]]\n","num_epochs = 5\n","loss_funcs = [CrossEntropyLoss()] * num_tasks\n","\n","model_params = {'num_labels':num_labels, 'num_tasks':num_tasks, \n","                'max_len':MAX_LEN,'label_ls':label_ls,\n","                'num_epochs':num_epochs, 'loss_funcs':loss_funcs,\n","                }\n","\n","results = run_models(save_path = SAVE_PATH, model_class=model_class, device=device, \n","     train_tensor=train_tensor, test_tensor=test_tensor, seed_list=[123],\n","      **model_params )"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["========== Trying seed 123 ==========\n","Multitask training: 3 tasks \n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Multitask training: 3 tasks \n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Running Epoch  0\n","Training loss : [113.9016785621643, 66.7609500437975, 113.84147441387177]. Validation loss: []. Duration: 181.5378189086914\n","Running Epoch  1\n","Training loss : [81.22452062368393, 37.06661168858409, 81.17453762888908]. Validation loss: []. Duration: 181.59448671340942\n","Running Epoch  2\n","Training loss : [62.693774700164795, 25.703176317736506, 62.341469280421734]. Validation loss: []. Duration: 181.61190056800842\n","Running Epoch  3\n","Training loss : [43.530984457582235, 14.478155992925167, 42.96935683116317]. Validation loss: []. Duration: 181.5128378868103\n","Running Epoch  4\n","Training loss : [29.352030855603516, 8.13306221854873, 29.39852475374937]. Validation loss: []. Duration: 181.56238079071045\n","num_tasks 3\n","\n","-----Report for task 0:-----\n","\n","precision: [0.81481481 0.65267176 0.80327869]\n","recall   : [0.88       0.83414634 0.5025641 ]\n","fscore   : [0.84615385 0.73233405 0.61829653]\n","support  : [200 205 195]\n","\n","-----Report for task 1:-----\n","\n","precision: [0.81220657 0.93023256 0.         0.        ]\n","recall   : [0.865 0.9   0.    0.   ]\n","fscore   : [0.8377724  0.91486658 0.         0.        ]\n","support  : [200 400   0   0]\n","\n","-----Report for task 2:-----\n","\n","precision: [0.81395349 0.65019011 0.80327869]\n","recall   : [0.875      0.83414634 0.5025641 ]\n","fscore   : [0.84337349 0.73076923 0.61829653]\n","support  : [200 205 195]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vfnEBUbZqBuk","executionInfo":{"status":"ok","timestamp":1631170792924,"user_tz":420,"elapsed":14,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"2b05f505-a7d4-4412-ec11-c3e3ea47aad8"},"source":["results[123][0]['macro_metrics']"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7569217530215319, 0.7389034813425056, 0.7322614744105027]"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"Aa0E43BbaPrL","executionInfo":{"status":"ok","timestamp":1631170792925,"user_tz":420,"elapsed":8,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}}},"source":["specific_res = get_specific_results(results)\n","macro_res    = get_macro_results(results)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"HPpGBDuFRMcl","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1631170794026,"user_tz":420,"elapsed":1108,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"b6f90075-27e1-4331-e154-30078e2c04bf"},"source":["specific_res"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Normal</th>\n","      <th>Abusive</th>\n","      <th>Hate</th>\n","      <th>Neither/NA</th>\n","      <th>Anti-Asian</th>\n","      <th>Anti-Black</th>\n","      <th>Both</th>\n","      <th>No.Agg.</th>\n","      <th>Some.Agg.</th>\n","      <th>Very.Agg.</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.81 +- 0.0</td>\n","      <td>0.65 +- 0.0</td>\n","      <td>0.8 +- 0.0</td>\n","      <td>0.81 +- 0.0</td>\n","      <td>0.93 +- 0.0</td>\n","      <td>--</td>\n","      <td>--</td>\n","      <td>0.81 +- 0.0</td>\n","      <td>0.65 +- 0.0</td>\n","      <td>0.8 +- 0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.88 +- 0.0</td>\n","      <td>0.83 +- 0.0</td>\n","      <td>0.5 +- 0.0</td>\n","      <td>0.86 +- 0.0</td>\n","      <td>0.9 +- 0.0</td>\n","      <td>--</td>\n","      <td>--</td>\n","      <td>0.88 +- 0.0</td>\n","      <td>0.83 +- 0.0</td>\n","      <td>0.5 +- 0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.85 +- 0.0</td>\n","      <td>0.73 +- 0.0</td>\n","      <td>0.62 +- 0.0</td>\n","      <td>0.84 +- 0.0</td>\n","      <td>0.91 +- 0.0</td>\n","      <td>--</td>\n","      <td>--</td>\n","      <td>0.84 +- 0.0</td>\n","      <td>0.73 +- 0.0</td>\n","      <td>0.62 +- 0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Normal      Abusive         Hate  ...      No.Agg.    Some.Agg.    Very.Agg.\n","0  0.81 +- 0.0  0.65 +- 0.0   0.8 +- 0.0  ...  0.81 +- 0.0  0.65 +- 0.0   0.8 +- 0.0\n","1  0.88 +- 0.0  0.83 +- 0.0   0.5 +- 0.0  ...  0.88 +- 0.0  0.83 +- 0.0   0.5 +- 0.0\n","2  0.85 +- 0.0  0.73 +- 0.0  0.62 +- 0.0  ...  0.84 +- 0.0  0.73 +- 0.0  0.62 +- 0.0\n","\n","[3 rows x 10 columns]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"oF3hG4NhOV10","executionInfo":{"status":"ok","timestamp":1631170794027,"user_tz":420,"elapsed":11,"user":{"displayName":"Huy Nghiem","photoUrl":"","userId":"06903637911945605583"}},"outputId":"e6690b34-f463-4b41-feff-4565bcb44033"},"source":["macro_res"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.76 +- 0.0</td>\n","      <td>0.74 +- 0.0</td>\n","      <td>0.75 +- 0.0</td>\n","      <td>0.87 +- 0.0</td>\n","      <td>0.88 +- 0.0</td>\n","      <td>0.88 +- 0.0</td>\n","      <td>0.76 +- 0.0</td>\n","      <td>0.74 +- 0.0</td>\n","      <td>0.75 +- 0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             0            1            2  ...            6            7            8\n","0  0.76 +- 0.0  0.74 +- 0.0  0.75 +- 0.0  ...  0.76 +- 0.0  0.74 +- 0.0  0.75 +- 0.0\n","\n","[1 rows x 9 columns]"]},"metadata":{},"execution_count":24}]}]}